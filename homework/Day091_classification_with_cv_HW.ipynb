{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"Day091_classification_with_cv_HW.ipynb","version":"0.3.2","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"W1ECjQ991jP2","colab_type":"text"},"source":["## 作業\n","嘗試比較用 color histogram 和 HOG 特徵來訓練的 SVM 分類器在 cifar10 training 和 testing data 上準確度的差別"]},{"cell_type":"code","metadata":{"id":"PSk3rZe71jP3","colab_type":"code","colab":{}},"source":["import os\n","import keras\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # 使用 CPU\n","\n","import numpy as np\n","import cv2 # 載入 cv2 套件\n","import matplotlib.pyplot as plt\n","\n","train, test = keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p061wdnJ1jP5","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","y_train = y_train.astype(int)\n","y_test = y_test.astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V8p86w3k1jP7","colab_type":"text"},"source":["#### 產生直方圖特徵的訓練資料\n"]},{"cell_type":"code","metadata":{"id":"b-7MBwFF1jP8","colab_type":"code","colab":{}},"source":["x_train_histogram = []\n","x_test_histogram = []\n","\n","# 對於所有訓練資料\n","for i in range(len(x_train)):\n","    chans = cv2.split(x_train[i]) # 把圖像的 3 個 channel 切分出來\n","    # 對於所有 channel\n","    hist_feature = []\n","    for chan in chans:\n","        # 計算該 channel 的直方圖\n","        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n","        hist_feature.extend(hist.flatten())\n","    # 把計算的直方圖特徵收集起來\n","    x_train_histogram.append(hist_feature)\n","\n","# 對於所有測試資料也做一樣的處理\n","for i in range(len(x_test)):\n","    chans = cv2.split(x_test[i]) # 把圖像的 3 個 channel 切分出來\n","    # 對於所有 channel\n","    hist_feature = []\n","    for chan in chans:\n","        # 計算該 channel 的直方圖\n","        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n","        hist_feature.extend(hist.flatten())\n","    x_test_histogram.append(hist_feature)\n","\n","x_train_histogram = np.array(x_train_histogram)\n","x_test_histogram = np.array(x_test_histogram)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"POXSTGZe1jP-","colab_type":"text"},"source":["#### 產生 HOG 特徵的訓練資料\n","* HOG 特徵通過計算和統計圖像局部區域的梯度方向直方圖來構建特徵，具體細節不在我們涵蓋的範圍裡面，有興趣的同學請參考[補充資料](https://www.cnblogs.com/zyly/p/9651261.html)哦\n","\n","HOG: 方向梯度直方圖（Histogram of Oriented Gradient, HOG）特徵是一種在計算機視覺和圖像處理中用來進行物體檢測的特徵描述子。它通過計算和統計圖像局部區域的梯度方向直方圖來構成特徵。\n","\n","http://alex-phd.blogspot.com/2014/03/hog.html"]},{"cell_type":"code","metadata":{"id":"yPHZtHRd1jP-","colab_type":"code","colab":{}},"source":["# SZ=20\n","bin_n = 16 # Number of bins\n","\n","def hog(img):\n","    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n","    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n","    mag, ang = cv2.cartToPolar(gx, gy)\n","    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n","    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n","    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n","    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n","    hist = np.hstack(hists)     # hist is a 64 bit vector\n","    return hist.astype(np.float32)\n","\n","x_train_hog = np.array([hog(x) for x in x_train])\n","x_test_hog = np.array([hog(x) for x in x_test])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3gEEOhh01jQA","colab_type":"text"},"source":["#### SVM model\n","* SVM 是機器學習中一個經典的分類算法，具體細節有興趣可以參考 [該知乎上的解釋](https://www.zhihu.com/question/21094489)，我們這裡直接調用 opencv 中實現好的函數"]},{"cell_type":"markdown","metadata":{"id":"GfWFViRZ1jQB","colab_type":"text"},"source":["#### 用 histogram 特徵訓練 SVM 模型\n","* 訓練過程可能會花點時間，請等他一下"]},{"cell_type":"code","metadata":{"id":"iHRMhKo41jQC","colab_type":"code","colab":{}},"source":["SVM_hist = cv2.ml.SVM_create()\n","SVM_hist.setKernel(cv2.ml.SVM_LINEAR)\n","SVM_hist.setGamma(5.383)\n","SVM_hist.setType(cv2.ml.SVM_C_SVC)\n","SVM_hist.setC(2.67)\n","\n","#training\n","SVM_hist.train(x_train_histogram, cv2.ml.ROW_SAMPLE, y_train) #SVM用train, 非fit\n","\n","# prediction\n","_, y_hist_train = SVM_hist.predict(x_train_histogram)\n","_, y_hist_test = SVM_hist.predict(x_test_histogram)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-IMrj0zs73Nh","colab_type":"code","outputId":"d511502d-7dbf-487f-e688-d99b22a50db7","executionInfo":{"status":"ok","timestamp":1564134288081,"user_tz":-480,"elapsed":13831,"user":{"displayName":"Lucy Chen","photoUrl":"","userId":"18365808695772762959"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["y_hist_train[:5]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2.],\n","       [2.],\n","       [0.],\n","       [3.],\n","       [2.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"9wIVENDT_-6n","colab_type":"text"},"source":["甚麼方法評估好壞??"]},{"cell_type":"markdown","metadata":{"id":"7xPRaD4t1jQE","colab_type":"text"},"source":["#### 用 HOG 特徵訓練 SVM 模型\n","* 訓練過程可能會花點時間，請等他一下"]},{"cell_type":"code","metadata":{"id":"Rm5DkQPh1jQF","colab_type":"code","colab":{}},"source":["SVM_hog = cv2.ml.SVM_create()\n","SVM_hog.setKernel(cv2.ml.SVM_LINEAR)\n","SVM_hog.setGamma(5.383)\n","SVM_hog.setType(cv2.ml.SVM_C_SVC)\n","SVM_hog.setC(2.67)\n","\n","#training\n","SVM_hog.train(x_train_hog, cv2.ml.ROW_SAMPLE, y_train)\n","\n","# prediction\n","_, y_hog_train = SVM_hog.predict(x_train_hog)\n","_, y_hog_test = SVM_hog.predict(x_test_hog)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tvp9681bl1Wn","colab_type":"text"},"source":["嘗試比較用 color histogram 和 HOG 特徵來訓練的 SVM 分類器在 cifar10 training 和 testing data 上準確度的差別\n","\n","### 沒有metrics可用, 要自己寫"]},{"cell_type":"code","metadata":{"id":"_WgWvP1e4dN9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"outputId":"1f52041b-1cbf-4a37-85a2-bf341652e23d","executionInfo":{"status":"ok","timestamp":1564134296876,"user_tz":-480,"elapsed":22610,"user":{"displayName":"Lucy Chen","photoUrl":"","userId":"18365808695772762959"}}},"source":["print(\"-----Histogram result-----\")\n","print(\"Training acc:\", 100 * (y_hist_train == y_train).sum() / len(y_train), \"%\")\n","print(\"Testing acc:\", 100 * (y_hist_test == y_test ).sum() / len(y_test), \"%\")\n","\n","print(\"-----HOG result-----\")\n","print(\"Training acc:\", 100 * (y_hog_train == y_train).sum() / len(y_train), \"%\")\n","print(\"Testing acc:\", 100 * (y_hog_test == y_test ).sum() / len(y_test), \"%\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["-----Histogram result-----\n","Training acc: 12.078 %\n","Testing acc: 12.28 %\n","-----HOG result-----\n","Training acc: 23.624 %\n","Testing acc: 23.18 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DVt522OEmSET","colab_type":"text"},"source":["如果你看到非常低的準確率，別懷疑，就是那麼低！到這裡大致可以體會到，靠人工設計的特徵在簡單的任務上也許是堪用（該例子如果用的是 mnist 數據集，準確應該還是可以有 90% 以上，有興趣的可以自己嘗試替換一下，或者參考這個範例來跑看看），但複雜的情況，比如說分類的類別多起來，就能明顯感覺到這些特徵的不足之處了。"]}]}